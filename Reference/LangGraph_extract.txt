defined. We introduce a LangGraph configuration to explicitly map out agent workflows as a
directed graph, instead of hard-coding sequences. This will make it easier to add new pipelines and
• Testing & CI: We will strengthen the continuous integration pipeline to cover the new multi-agent
approvals, pipelines)
├── langgraph.yaml
# YAML definition of agent graph (nodes, edges,
records, docs, sessions
# Turborepo configuration (tasks pipeline for
contains the logic for each AI agent and the orchestrator ( langgraph.yaml plus helper code) – this
Automation Pipelines
A core feature of BrainStackStudio’s platform is the ability to run multi-step automation pipelines that
involve different AI agents and tools. Below we define the key automation pipelines the system will support,
workflows. Each pipeline is orchestrated via the LangGraph multi-agent system (defined in the next section),
ensuring a clear and flexible execution order. Key pipelines include:
blueprints, changelogs, content drafts) in Markdown format using Anthropic Claude. Pipeline: The
(e.g. posted to a Notion page or saved as a PDF). This pipeline replaces manual doc writing or
code from high-level specs. In this pipeline, Claude first produces a detailed technical specification
coding agent can follow exactly. The pipeline then feeds Claude’s output to Codex (GPT-4), which
automatically inserted into the repository or staged for review. This pipeline turns natural language design
the CI pipeline runs tests and linting to ensure nothing is broken (see CI/CD section). Only if tests pass will
up-to-date external information. Pipeline: When a task requires knowledge beyond the internal
is grounded in the retrieved information. The benefit of this pipeline is that Claude’s output will be
(tagged as research ) so that the context is logged for future reference or audits. This pipeline is
using iterative AI feedback. Pipeline: After content is generated (by Claude or a human), we use
restructuring for better engagement. In practice, the pipeline might: (1) call Gemini with a prompt
editors time. This pipeline leverages Gemini’s strengths (which might include nuanced
distribute or archive them appropriately. Pipeline: Many tasks culminate in producing files – e.g. a
respective tasks and then packaged together for review. The pipeline coordinating this would use
publishing pipeline: generate content -> optimize it -> format it -> deliver it, replacing what might
Each of these pipelines is defined in the LangGraph (see below) so that the sequence of agents and actions
is declarative. Operators can trigger these pipelines manually (via the dashboard UI or Slack commands) or
a bundle pipeline to onboard a customer). All pipelines are designed to be retryable and traceable: if any
retries and escalation as described later). By using LLMs as the building blocks, these automation pipelines
LangGraph Multi-Agent Routing
To coordinate the above pipelines, we introduce LangGraph, a YAML-defined graph of agents and decision
nodes that routes tasks to the appropriate AI model or tool in sequence. LangGraph provides a high-level
YAML Structure: The agents/langgraph.yaml file will define the nodes, edges, and any conditional
# pipeline definition
# end of pipeline (code files ready)
In this YAML, agents defines each node: Claude (id claude_max ) is configured as a large-context model
input to the next. The flows section then strings these nodes together for specific named pipelines. For
logic can be supported either by YAML (with a condition field as shown) or handled in code by the
Routing Logic: The LangGraph orchestrator ( agents/base.py or similar) will read the YAML graph and
handle the execution logic. When a request comes in to run a pipeline (for example, the /task/generate
endpoint might correspond to a flow name in the YAML), the orchestrator starts at the start node and
YAML to allow a node to have multiple next options with conditions, or have a special “router” node type).
For instance, we might have a classifier agent at the start that decides which pipeline to follow (“chain
need to inject relevant memory or knowledge. Rather than clutter the YAML with that, the orchestrator
injection 25 – those will be refactored to use the unified LangGraph approach, so that if we ever change
POST /pipeline/run that accepts a JSON like {"flow": "spec_to_code", "inputs": { ... } }
LangGraph executor. This keeps the external API simple while the internal logic is governed by the YAML.
(Gemini)” in the UI). The YAML will allow defining composite flows too – e.g. a chain that actually runs
In summary, LangGraph gives us a flexible, configurable brain for the system. We can update
langgraph.yaml to tweak our automation pipelines (add a new step, change which model is used for a
guided by a centrally defined playbook (the LangGraph).
Database Schema: The main entities we need to store are Tasks, Prompts, Sessions, Docs, and
Tracks chat sessions or ongoing conversations. Each
session can be associated with a user (or system if
it's an agent-only session), and we record when it
started and last active time. The session id will be
sessions
summary or important facts of the session,
interactions – the frontend can start a new session or
continue an existing one by passing the session ID to
memory to that session. It also allows listing past
chat sessions in the UI, resuming them, or cleaning
covered by sessions + entries in memory or prompts (depending on how we log chat messages). We
consolidate those into a single pipeline. We will ensure to attach metadata: for example, each chunk could
session from memory (or tasks table) to include as “Recent history” 23 . We can also retrieve any global
our autopublish_content or similar pipeline with context from that task. Similarly, if one of our
pipeline), and push it back. Implementation might involve periodic polling or a Notion integration
a successful payment (new sale) 58 . On receiving a checkout.session.completed or similar
completed, it calls a deployment pipeline). Initially, though, our needs can be met with direct calls in
deciding escalation) to manage the pipeline. This combination of traditional programming (for guarantees
context like default model and knowledge base project). The system might then run a pipeline: fetch
• User Authentication and Session: Depending on context, MyRoofGenius Copilot might require user
admin monitoring the copilot’s conversations. If needed, the system’s memory and session model
require login or a session).
Metadata tags can be embedded as HTML comments or YAML front matter. For example, we might include
a YAML front matter at the top of an SOP like:
and consistent so that any downstream process (like publishing pipelines) can detect them.
pipeline
tasks and pipeline flows (non-chat).
nl-design (invoke design pipeline Claude->
POST /pipeline/run (generic pipeline trig
LangGraph internally.
langgraph.yaml
YAML configuration defining the agent
the LangGraph section).
LangGraph. Includes a parser for the
YAML and an executor that can run a
lookup node definitions from YAML (or a pre-l
load_graph_config() to parse YAML on s
pipelines: e.g. uses Claude to draft
pipeline). The current system had
of outputs (for QA pipeline).
(maybe from two time ranges or sessions) an
if checkout.session.completed , call
{"session_id": ...,
LangGraph
If implemented: fetch langgraph.yaml (maybe the
e.g. sessionStorage. Also include logout() that
perhaps a fixed model or a session_id tied to user if
(new session id).
pipeline automating
render.yaml (in
provided render.yaml
create base.py and langgraph.yaml ; when exposing new endpoints, we know exactly which route file
returns result to UI; multi-step pipelines produce the intended outcomes; memory search returns relevant
To ensure smooth and reliable releases of the BrainStackStudio platform, we will set up a CI/CD pipeline
{{ variable }} by rendering them with dummy data. - Build Artifacts: If tests pass, the pipeline will
Render.com for hosting the FastAPI service (as indicated by README). The pipeline can automatically deploy
configured, reading render.yaml . We'll ensure render.yaml is updated to include any new env vars
pipeline can integrate with Vercel: either use Vercel’s Git integration (so any push triggers Vercel build) or
pipeline (or render start command) should run alembic upgrade head automatically so the Supabase/
Claude/Codex Pipeline in CI/CD: The user asked for "Claude file → test → deploy (Codex pipeline)". This
Given the question’s phrasing, at minimum, we ensure our pipeline connects the pieces: - For now, the
blueprint. Our pipeline tests after the code is produced by Codex manually or semi-manually.
